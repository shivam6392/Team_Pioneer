{
  "best_global_step": 10010,
  "best_metric": 0.7221915430630643,
  "best_model_checkpoint": "./segformer_offroad_output/checkpoint-10010",
  "epoch": 14.0,
  "eval_steps": 500,
  "global_step": 10010,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07000350017500875,
      "grad_norm": 3.542855739593506,
      "learning_rate": 5.972587412587413e-05,
      "loss": 0.8624,
      "step": 50
    },
    {
      "epoch": 0.1400070003500175,
      "grad_norm": 4.8365325927734375,
      "learning_rate": 5.944615384615385e-05,
      "loss": 0.6505,
      "step": 100
    },
    {
      "epoch": 0.21001050052502626,
      "grad_norm": 2.723144769668579,
      "learning_rate": 5.916643356643357e-05,
      "loss": 0.5953,
      "step": 150
    },
    {
      "epoch": 0.280014000700035,
      "grad_norm": 1.3732106685638428,
      "learning_rate": 5.888671328671328e-05,
      "loss": 0.5432,
      "step": 200
    },
    {
      "epoch": 0.35001750087504374,
      "grad_norm": 2.8519270420074463,
      "learning_rate": 5.8606993006993006e-05,
      "loss": 0.5018,
      "step": 250
    },
    {
      "epoch": 0.4200210010500525,
      "grad_norm": 0.9715609550476074,
      "learning_rate": 5.832727272727273e-05,
      "loss": 0.4694,
      "step": 300
    },
    {
      "epoch": 0.49002450122506125,
      "grad_norm": 5.335691928863525,
      "learning_rate": 5.804755244755245e-05,
      "loss": 0.4332,
      "step": 350
    },
    {
      "epoch": 0.56002800140007,
      "grad_norm": 0.7358528971672058,
      "learning_rate": 5.776783216783217e-05,
      "loss": 0.4254,
      "step": 400
    },
    {
      "epoch": 0.6300315015750787,
      "grad_norm": 67.27679443359375,
      "learning_rate": 5.748811188811189e-05,
      "loss": 0.4423,
      "step": 450
    },
    {
      "epoch": 0.7000350017500875,
      "grad_norm": 2.140598773956299,
      "learning_rate": 5.720839160839161e-05,
      "loss": 0.4268,
      "step": 500
    },
    {
      "epoch": 0.7700385019250963,
      "grad_norm": 2.8103785514831543,
      "learning_rate": 5.692867132867133e-05,
      "loss": 0.4363,
      "step": 550
    },
    {
      "epoch": 0.840042002100105,
      "grad_norm": 2.2708582878112793,
      "learning_rate": 5.664895104895105e-05,
      "loss": 0.3856,
      "step": 600
    },
    {
      "epoch": 0.9100455022751137,
      "grad_norm": 0.7346077561378479,
      "learning_rate": 5.636923076923077e-05,
      "loss": 0.4105,
      "step": 650
    },
    {
      "epoch": 0.9800490024501225,
      "grad_norm": 1.4381853342056274,
      "learning_rate": 5.608951048951049e-05,
      "loss": 0.4111,
      "step": 700
    },
    {
      "epoch": 1.0,
      "eval_accuracy_landscape": 0.7269319682256915,
      "eval_loss": 0.3915799558162689,
      "eval_mean_accuracy": 0.8243535930945308,
      "eval_mean_iou": 0.6749962077635014,
      "eval_runtime": 85.3439,
      "eval_samples_per_second": 3.714,
      "eval_steps_per_second": 3.714,
      "step": 715
    },
    {
      "epoch": 1.0490024501225061,
      "grad_norm": 1.6092631816864014,
      "learning_rate": 5.5809790209790215e-05,
      "loss": 0.392,
      "step": 750
    },
    {
      "epoch": 1.119005950297515,
      "grad_norm": 2.0869786739349365,
      "learning_rate": 5.5530069930069926e-05,
      "loss": 0.3917,
      "step": 800
    },
    {
      "epoch": 1.1890094504725237,
      "grad_norm": 2.9887914657592773,
      "learning_rate": 5.525034965034965e-05,
      "loss": 0.385,
      "step": 850
    },
    {
      "epoch": 1.2590129506475325,
      "grad_norm": 2.5140295028686523,
      "learning_rate": 5.4970629370629374e-05,
      "loss": 0.358,
      "step": 900
    },
    {
      "epoch": 1.329016450822541,
      "grad_norm": 1.0156329870224,
      "learning_rate": 5.469090909090909e-05,
      "loss": 0.3867,
      "step": 950
    },
    {
      "epoch": 1.3990199509975498,
      "grad_norm": 6.714869499206543,
      "learning_rate": 5.4411188811188816e-05,
      "loss": 0.3632,
      "step": 1000
    },
    {
      "epoch": 1.4690234511725586,
      "grad_norm": 2.55135440826416,
      "learning_rate": 5.413146853146853e-05,
      "loss": 0.3684,
      "step": 1050
    },
    {
      "epoch": 1.5390269513475674,
      "grad_norm": 1.8679678440093994,
      "learning_rate": 5.385174825174825e-05,
      "loss": 0.3676,
      "step": 1100
    },
    {
      "epoch": 1.6090304515225762,
      "grad_norm": 2.2477505207061768,
      "learning_rate": 5.357202797202797e-05,
      "loss": 0.3644,
      "step": 1150
    },
    {
      "epoch": 1.6790339516975847,
      "grad_norm": 0.9277704358100891,
      "learning_rate": 5.329230769230769e-05,
      "loss": 0.3363,
      "step": 1200
    },
    {
      "epoch": 1.7490374518725935,
      "grad_norm": 1.8591198921203613,
      "learning_rate": 5.3012587412587417e-05,
      "loss": 0.3538,
      "step": 1250
    },
    {
      "epoch": 1.8190409520476023,
      "grad_norm": 2.8858516216278076,
      "learning_rate": 5.2732867132867134e-05,
      "loss": 0.338,
      "step": 1300
    },
    {
      "epoch": 1.889044452222611,
      "grad_norm": 12.8694486618042,
      "learning_rate": 5.245314685314686e-05,
      "loss": 0.3617,
      "step": 1350
    },
    {
      "epoch": 1.9590479523976199,
      "grad_norm": 1.1632415056228638,
      "learning_rate": 5.2173426573426576e-05,
      "loss": 0.3343,
      "step": 1400
    },
    {
      "epoch": 2.0,
      "eval_accuracy_landscape": 0.7408890120430307,
      "eval_loss": 0.35229426622390747,
      "eval_mean_accuracy": 0.8225138352399157,
      "eval_mean_iou": 0.6966842108092139,
      "eval_runtime": 56.4781,
      "eval_samples_per_second": 5.613,
      "eval_steps_per_second": 5.613,
      "step": 1430
    },
    {
      "epoch": 2.0280014000700035,
      "grad_norm": 1.773048758506775,
      "learning_rate": 5.189370629370629e-05,
      "loss": 0.3595,
      "step": 1450
    },
    {
      "epoch": 2.0980049002450123,
      "grad_norm": 1.9858700037002563,
      "learning_rate": 5.161398601398601e-05,
      "loss": 0.356,
      "step": 1500
    },
    {
      "epoch": 2.168008400420021,
      "grad_norm": 4.068734645843506,
      "learning_rate": 5.1334265734265735e-05,
      "loss": 0.3404,
      "step": 1550
    },
    {
      "epoch": 2.23801190059503,
      "grad_norm": 5.003993988037109,
      "learning_rate": 5.105454545454546e-05,
      "loss": 0.3425,
      "step": 1600
    },
    {
      "epoch": 2.3080154007700386,
      "grad_norm": 4.3835015296936035,
      "learning_rate": 5.077482517482518e-05,
      "loss": 0.3427,
      "step": 1650
    },
    {
      "epoch": 2.3780189009450474,
      "grad_norm": 0.8118716478347778,
      "learning_rate": 5.04951048951049e-05,
      "loss": 0.3431,
      "step": 1700
    },
    {
      "epoch": 2.448022401120056,
      "grad_norm": 0.9688817858695984,
      "learning_rate": 5.021538461538461e-05,
      "loss": 0.325,
      "step": 1750
    },
    {
      "epoch": 2.518025901295065,
      "grad_norm": 1.2204984426498413,
      "learning_rate": 4.9935664335664336e-05,
      "loss": 0.3231,
      "step": 1800
    },
    {
      "epoch": 2.5880294014700738,
      "grad_norm": 0.932293713092804,
      "learning_rate": 4.965594405594406e-05,
      "loss": 0.3324,
      "step": 1850
    },
    {
      "epoch": 2.658032901645082,
      "grad_norm": 1.2717713117599487,
      "learning_rate": 4.937622377622378e-05,
      "loss": 0.3103,
      "step": 1900
    },
    {
      "epoch": 2.728036401820091,
      "grad_norm": 0.8849971294403076,
      "learning_rate": 4.90965034965035e-05,
      "loss": 0.3192,
      "step": 1950
    },
    {
      "epoch": 2.7980399019950997,
      "grad_norm": 5.3747453689575195,
      "learning_rate": 4.881678321678322e-05,
      "loss": 0.3153,
      "step": 2000
    },
    {
      "epoch": 2.8680434021701084,
      "grad_norm": 8.191831588745117,
      "learning_rate": 4.853706293706294e-05,
      "loss": 0.3169,
      "step": 2050
    },
    {
      "epoch": 2.9380469023451172,
      "grad_norm": 1.401676893234253,
      "learning_rate": 4.8257342657342654e-05,
      "loss": 0.3274,
      "step": 2100
    },
    {
      "epoch": 3.0,
      "eval_accuracy_landscape": 0.7863235761910962,
      "eval_loss": 0.3457789123058319,
      "eval_mean_accuracy": 0.8320608480779224,
      "eval_mean_iou": 0.7019270180189353,
      "eval_runtime": 52.6809,
      "eval_samples_per_second": 6.017,
      "eval_steps_per_second": 6.017,
      "step": 2145
    },
    {
      "epoch": 3.007000350017501,
      "grad_norm": 1.0618163347244263,
      "learning_rate": 4.797762237762238e-05,
      "loss": 0.3261,
      "step": 2150
    },
    {
      "epoch": 3.0770038501925097,
      "grad_norm": 3.7079756259918213,
      "learning_rate": 4.76979020979021e-05,
      "loss": 0.3082,
      "step": 2200
    },
    {
      "epoch": 3.1470073503675184,
      "grad_norm": 0.8971448540687561,
      "learning_rate": 4.741818181818182e-05,
      "loss": 0.3232,
      "step": 2250
    },
    {
      "epoch": 3.2170108505425272,
      "grad_norm": 0.4792216718196869,
      "learning_rate": 4.7138461538461544e-05,
      "loss": 0.3245,
      "step": 2300
    },
    {
      "epoch": 3.287014350717536,
      "grad_norm": 1.5664951801300049,
      "learning_rate": 4.6858741258741255e-05,
      "loss": 0.3283,
      "step": 2350
    },
    {
      "epoch": 3.357017850892545,
      "grad_norm": 0.9241160154342651,
      "learning_rate": 4.657902097902098e-05,
      "loss": 0.3083,
      "step": 2400
    },
    {
      "epoch": 3.4270213510675536,
      "grad_norm": 2.072594165802002,
      "learning_rate": 4.62993006993007e-05,
      "loss": 0.3034,
      "step": 2450
    },
    {
      "epoch": 3.4970248512425623,
      "grad_norm": 2.511852264404297,
      "learning_rate": 4.601958041958042e-05,
      "loss": 0.3186,
      "step": 2500
    },
    {
      "epoch": 3.567028351417571,
      "grad_norm": 1.8896443843841553,
      "learning_rate": 4.5739860139860145e-05,
      "loss": 0.302,
      "step": 2550
    },
    {
      "epoch": 3.6370318515925795,
      "grad_norm": 0.9908666610717773,
      "learning_rate": 4.546013986013986e-05,
      "loss": 0.3287,
      "step": 2600
    },
    {
      "epoch": 3.7070353517675882,
      "grad_norm": 1.3437225818634033,
      "learning_rate": 4.518041958041958e-05,
      "loss": 0.3257,
      "step": 2650
    },
    {
      "epoch": 3.777038851942597,
      "grad_norm": 0.5786551237106323,
      "learning_rate": 4.49006993006993e-05,
      "loss": 0.3016,
      "step": 2700
    },
    {
      "epoch": 3.847042352117606,
      "grad_norm": 0.8083388805389404,
      "learning_rate": 4.462097902097902e-05,
      "loss": 0.2971,
      "step": 2750
    },
    {
      "epoch": 3.9170458522926146,
      "grad_norm": 1.4448152780532837,
      "learning_rate": 4.4341258741258746e-05,
      "loss": 0.3209,
      "step": 2800
    },
    {
      "epoch": 3.9870493524676234,
      "grad_norm": 1.705259919166565,
      "learning_rate": 4.4061538461538463e-05,
      "loss": 0.3108,
      "step": 2850
    },
    {
      "epoch": 4.0,
      "eval_accuracy_landscape": 0.7696874404575934,
      "eval_loss": 0.35165297985076904,
      "eval_mean_accuracy": 0.8392320144698329,
      "eval_mean_iou": 0.705334813737341,
      "eval_runtime": 58.2041,
      "eval_samples_per_second": 5.446,
      "eval_steps_per_second": 5.446,
      "step": 2860
    },
    {
      "epoch": 4.056002800140007,
      "grad_norm": 0.6003116369247437,
      "learning_rate": 4.378181818181819e-05,
      "loss": 0.3073,
      "step": 2900
    },
    {
      "epoch": 4.126006300315016,
      "grad_norm": 0.6464124321937561,
      "learning_rate": 4.35020979020979e-05,
      "loss": 0.3138,
      "step": 2950
    },
    {
      "epoch": 4.196009800490025,
      "grad_norm": 0.7319393754005432,
      "learning_rate": 4.322237762237762e-05,
      "loss": 0.3099,
      "step": 3000
    },
    {
      "epoch": 4.266013300665033,
      "grad_norm": 1.1062824726104736,
      "learning_rate": 4.294265734265734e-05,
      "loss": 0.2979,
      "step": 3050
    },
    {
      "epoch": 4.336016800840042,
      "grad_norm": 0.5430461168289185,
      "learning_rate": 4.2662937062937064e-05,
      "loss": 0.316,
      "step": 3100
    },
    {
      "epoch": 4.406020301015051,
      "grad_norm": 1.2849128246307373,
      "learning_rate": 4.238321678321679e-05,
      "loss": 0.3045,
      "step": 3150
    },
    {
      "epoch": 4.47602380119006,
      "grad_norm": 1.7356597185134888,
      "learning_rate": 4.2103496503496506e-05,
      "loss": 0.2921,
      "step": 3200
    },
    {
      "epoch": 4.5460273013650685,
      "grad_norm": 0.5658629536628723,
      "learning_rate": 4.1823776223776223e-05,
      "loss": 0.307,
      "step": 3250
    },
    {
      "epoch": 4.616030801540077,
      "grad_norm": 0.6467218995094299,
      "learning_rate": 4.154405594405594e-05,
      "loss": 0.2849,
      "step": 3300
    },
    {
      "epoch": 4.686034301715086,
      "grad_norm": 1.3883693218231201,
      "learning_rate": 4.1264335664335665e-05,
      "loss": 0.3058,
      "step": 3350
    },
    {
      "epoch": 4.756037801890095,
      "grad_norm": 0.7155978083610535,
      "learning_rate": 4.098461538461538e-05,
      "loss": 0.3029,
      "step": 3400
    },
    {
      "epoch": 4.826041302065104,
      "grad_norm": 0.5027921795845032,
      "learning_rate": 4.070489510489511e-05,
      "loss": 0.3139,
      "step": 3450
    },
    {
      "epoch": 4.896044802240112,
      "grad_norm": 2.3347058296203613,
      "learning_rate": 4.042517482517483e-05,
      "loss": 0.2925,
      "step": 3500
    },
    {
      "epoch": 4.966048302415121,
      "grad_norm": 0.5990805625915527,
      "learning_rate": 4.014545454545455e-05,
      "loss": 0.3021,
      "step": 3550
    },
    {
      "epoch": 5.0,
      "eval_accuracy_landscape": 0.7695665586154433,
      "eval_loss": 0.3460943102836609,
      "eval_mean_accuracy": 0.8471310733933112,
      "eval_mean_iou": 0.7049267397276824,
      "eval_runtime": 63.642,
      "eval_samples_per_second": 4.981,
      "eval_steps_per_second": 4.981,
      "step": 3575
    },
    {
      "epoch": 5.035001750087504,
      "grad_norm": 0.8966060876846313,
      "learning_rate": 3.9865734265734266e-05,
      "loss": 0.3095,
      "step": 3600
    },
    {
      "epoch": 5.105005250262513,
      "grad_norm": 0.6030834913253784,
      "learning_rate": 3.9586013986013983e-05,
      "loss": 0.2838,
      "step": 3650
    },
    {
      "epoch": 5.175008750437522,
      "grad_norm": 0.7920395731925964,
      "learning_rate": 3.930629370629371e-05,
      "loss": 0.2952,
      "step": 3700
    },
    {
      "epoch": 5.245012250612531,
      "grad_norm": 0.6947031617164612,
      "learning_rate": 3.902657342657343e-05,
      "loss": 0.2941,
      "step": 3750
    },
    {
      "epoch": 5.3150157507875395,
      "grad_norm": 0.6948520541191101,
      "learning_rate": 3.874685314685315e-05,
      "loss": 0.2884,
      "step": 3800
    },
    {
      "epoch": 5.385019250962548,
      "grad_norm": 0.6012511253356934,
      "learning_rate": 3.8467132867132874e-05,
      "loss": 0.2956,
      "step": 3850
    },
    {
      "epoch": 5.455022751137557,
      "grad_norm": 1.4166512489318848,
      "learning_rate": 3.8187412587412584e-05,
      "loss": 0.2986,
      "step": 3900
    },
    {
      "epoch": 5.525026251312566,
      "grad_norm": 0.47441568970680237,
      "learning_rate": 3.790769230769231e-05,
      "loss": 0.3072,
      "step": 3950
    },
    {
      "epoch": 5.595029751487575,
      "grad_norm": 1.2158414125442505,
      "learning_rate": 3.7627972027972026e-05,
      "loss": 0.2988,
      "step": 4000
    },
    {
      "epoch": 5.665033251662583,
      "grad_norm": 0.934528648853302,
      "learning_rate": 3.734825174825175e-05,
      "loss": 0.299,
      "step": 4050
    },
    {
      "epoch": 5.735036751837592,
      "grad_norm": 1.930142879486084,
      "learning_rate": 3.7068531468531475e-05,
      "loss": 0.3035,
      "step": 4100
    },
    {
      "epoch": 5.805040252012601,
      "grad_norm": 0.4864594042301178,
      "learning_rate": 3.678881118881119e-05,
      "loss": 0.3138,
      "step": 4150
    },
    {
      "epoch": 5.87504375218761,
      "grad_norm": 0.5483366847038269,
      "learning_rate": 3.650909090909091e-05,
      "loss": 0.2806,
      "step": 4200
    },
    {
      "epoch": 5.9450472523626186,
      "grad_norm": 0.8634029030799866,
      "learning_rate": 3.622937062937063e-05,
      "loss": 0.2913,
      "step": 4250
    },
    {
      "epoch": 6.0,
      "eval_accuracy_landscape": 0.7243959299468464,
      "eval_loss": 0.3493977189064026,
      "eval_mean_accuracy": 0.8329498076968209,
      "eval_mean_iou": 0.6972388229385763,
      "eval_runtime": 53.0564,
      "eval_samples_per_second": 5.975,
      "eval_steps_per_second": 5.975,
      "step": 4290
    },
    {
      "epoch": 6.014000700035002,
      "grad_norm": 0.7314888834953308,
      "learning_rate": 3.594965034965035e-05,
      "loss": 0.2975,
      "step": 4300
    },
    {
      "epoch": 6.0840042002100105,
      "grad_norm": 0.4906451404094696,
      "learning_rate": 3.566993006993007e-05,
      "loss": 0.2924,
      "step": 4350
    },
    {
      "epoch": 6.154007700385019,
      "grad_norm": 0.6243793368339539,
      "learning_rate": 3.539020979020979e-05,
      "loss": 0.2975,
      "step": 4400
    },
    {
      "epoch": 6.224011200560028,
      "grad_norm": 0.690330445766449,
      "learning_rate": 3.511048951048952e-05,
      "loss": 0.3068,
      "step": 4450
    },
    {
      "epoch": 6.294014700735037,
      "grad_norm": 0.7524462938308716,
      "learning_rate": 3.483076923076923e-05,
      "loss": 0.2935,
      "step": 4500
    },
    {
      "epoch": 6.364018200910046,
      "grad_norm": 7.766578197479248,
      "learning_rate": 3.455104895104895e-05,
      "loss": 0.2951,
      "step": 4550
    },
    {
      "epoch": 6.4340217010850544,
      "grad_norm": 0.9714937210083008,
      "learning_rate": 3.427132867132867e-05,
      "loss": 0.2924,
      "step": 4600
    },
    {
      "epoch": 6.504025201260063,
      "grad_norm": 1.0950431823730469,
      "learning_rate": 3.3991608391608394e-05,
      "loss": 0.2965,
      "step": 4650
    },
    {
      "epoch": 6.574028701435072,
      "grad_norm": 0.7783877849578857,
      "learning_rate": 3.371188811188811e-05,
      "loss": 0.2793,
      "step": 4700
    },
    {
      "epoch": 6.644032201610081,
      "grad_norm": 0.6225411891937256,
      "learning_rate": 3.3432167832167835e-05,
      "loss": 0.3019,
      "step": 4750
    },
    {
      "epoch": 6.71403570178509,
      "grad_norm": 0.3779922425746918,
      "learning_rate": 3.315244755244755e-05,
      "loss": 0.2879,
      "step": 4800
    },
    {
      "epoch": 6.784039201960098,
      "grad_norm": 1.6899769306182861,
      "learning_rate": 3.287272727272727e-05,
      "loss": 0.2934,
      "step": 4850
    },
    {
      "epoch": 6.854042702135107,
      "grad_norm": 1.4678473472595215,
      "learning_rate": 3.2593006993006995e-05,
      "loss": 0.2735,
      "step": 4900
    },
    {
      "epoch": 6.924046202310116,
      "grad_norm": 0.9627324342727661,
      "learning_rate": 3.231328671328671e-05,
      "loss": 0.286,
      "step": 4950
    },
    {
      "epoch": 6.994049702485125,
      "grad_norm": 1.9154105186462402,
      "learning_rate": 3.2033566433566436e-05,
      "loss": 0.2883,
      "step": 5000
    },
    {
      "epoch": 7.0,
      "eval_accuracy_landscape": 0.7486457993964817,
      "eval_loss": 0.34246259927749634,
      "eval_mean_accuracy": 0.8457026600536097,
      "eval_mean_iou": 0.7062635884841995,
      "eval_runtime": 52.8816,
      "eval_samples_per_second": 5.995,
      "eval_steps_per_second": 5.995,
      "step": 5005
    },
    {
      "epoch": 7.063003150157508,
      "grad_norm": 0.7984289526939392,
      "learning_rate": 3.175384615384616e-05,
      "loss": 0.2883,
      "step": 5050
    },
    {
      "epoch": 7.133006650332517,
      "grad_norm": 0.4829264283180237,
      "learning_rate": 3.147412587412587e-05,
      "loss": 0.2888,
      "step": 5100
    },
    {
      "epoch": 7.2030101505075255,
      "grad_norm": 0.8177937865257263,
      "learning_rate": 3.1194405594405595e-05,
      "loss": 0.2805,
      "step": 5150
    },
    {
      "epoch": 7.273013650682534,
      "grad_norm": 1.7361618280410767,
      "learning_rate": 3.091468531468531e-05,
      "loss": 0.2865,
      "step": 5200
    },
    {
      "epoch": 7.343017150857543,
      "grad_norm": 0.4006812572479248,
      "learning_rate": 3.063496503496504e-05,
      "loss": 0.2822,
      "step": 5250
    },
    {
      "epoch": 7.413020651032552,
      "grad_norm": 0.9847764372825623,
      "learning_rate": 3.0355244755244755e-05,
      "loss": 0.2914,
      "step": 5300
    },
    {
      "epoch": 7.483024151207561,
      "grad_norm": 0.973183810710907,
      "learning_rate": 3.0075524475524475e-05,
      "loss": 0.296,
      "step": 5350
    },
    {
      "epoch": 7.553027651382569,
      "grad_norm": 0.9839587211608887,
      "learning_rate": 2.9795804195804196e-05,
      "loss": 0.2758,
      "step": 5400
    },
    {
      "epoch": 7.623031151557578,
      "grad_norm": 1.3103148937225342,
      "learning_rate": 2.9516083916083917e-05,
      "loss": 0.2847,
      "step": 5450
    },
    {
      "epoch": 7.693034651732587,
      "grad_norm": 0.5326080918312073,
      "learning_rate": 2.9236363636363635e-05,
      "loss": 0.294,
      "step": 5500
    },
    {
      "epoch": 7.763038151907596,
      "grad_norm": 0.3448418378829956,
      "learning_rate": 2.895664335664336e-05,
      "loss": 0.2836,
      "step": 5550
    },
    {
      "epoch": 7.8330416520826045,
      "grad_norm": 0.6348124742507935,
      "learning_rate": 2.867692307692308e-05,
      "loss": 0.2812,
      "step": 5600
    },
    {
      "epoch": 7.903045152257613,
      "grad_norm": 0.57177734375,
      "learning_rate": 2.8397202797202797e-05,
      "loss": 0.281,
      "step": 5650
    },
    {
      "epoch": 7.973048652432622,
      "grad_norm": 2.133378505706787,
      "learning_rate": 2.8117482517482518e-05,
      "loss": 0.3014,
      "step": 5700
    },
    {
      "epoch": 8.0,
      "eval_accuracy_landscape": 0.7540890257308239,
      "eval_loss": 0.33008596301078796,
      "eval_mean_accuracy": 0.8428082220924997,
      "eval_mean_iou": 0.7117860515098229,
      "eval_runtime": 55.7127,
      "eval_samples_per_second": 5.69,
      "eval_steps_per_second": 5.69,
      "step": 5720
    },
    {
      "epoch": 8.042002100105005,
      "grad_norm": 5.251916885375977,
      "learning_rate": 2.783776223776224e-05,
      "loss": 0.2885,
      "step": 5750
    },
    {
      "epoch": 8.112005600280014,
      "grad_norm": 0.826423704624176,
      "learning_rate": 2.7558041958041956e-05,
      "loss": 0.2809,
      "step": 5800
    },
    {
      "epoch": 8.182009100455023,
      "grad_norm": 3.31638765335083,
      "learning_rate": 2.727832167832168e-05,
      "loss": 0.2842,
      "step": 5850
    },
    {
      "epoch": 8.252012600630032,
      "grad_norm": 1.3924670219421387,
      "learning_rate": 2.69986013986014e-05,
      "loss": 0.279,
      "step": 5900
    },
    {
      "epoch": 8.32201610080504,
      "grad_norm": 0.5765440464019775,
      "learning_rate": 2.671888111888112e-05,
      "loss": 0.3029,
      "step": 5950
    },
    {
      "epoch": 8.39201960098005,
      "grad_norm": 6.654693126678467,
      "learning_rate": 2.643916083916084e-05,
      "loss": 0.2919,
      "step": 6000
    },
    {
      "epoch": 8.462023101155058,
      "grad_norm": 1.326346755027771,
      "learning_rate": 2.615944055944056e-05,
      "loss": 0.2812,
      "step": 6050
    },
    {
      "epoch": 8.532026601330067,
      "grad_norm": 1.2071527242660522,
      "learning_rate": 2.5879720279720278e-05,
      "loss": 0.285,
      "step": 6100
    },
    {
      "epoch": 8.602030101505076,
      "grad_norm": 2.2254881858825684,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 0.2787,
      "step": 6150
    },
    {
      "epoch": 8.672033601680084,
      "grad_norm": 0.932446300983429,
      "learning_rate": 2.5320279720279723e-05,
      "loss": 0.2806,
      "step": 6200
    },
    {
      "epoch": 8.742037101855093,
      "grad_norm": 2.5406532287597656,
      "learning_rate": 2.504055944055944e-05,
      "loss": 0.2776,
      "step": 6250
    },
    {
      "epoch": 8.812040602030102,
      "grad_norm": 0.7723379135131836,
      "learning_rate": 2.476083916083916e-05,
      "loss": 0.2814,
      "step": 6300
    },
    {
      "epoch": 8.88204410220511,
      "grad_norm": 0.5599589347839355,
      "learning_rate": 2.4481118881118882e-05,
      "loss": 0.2916,
      "step": 6350
    },
    {
      "epoch": 8.95204760238012,
      "grad_norm": 0.3891904056072235,
      "learning_rate": 2.42013986013986e-05,
      "loss": 0.2782,
      "step": 6400
    },
    {
      "epoch": 9.0,
      "eval_accuracy_landscape": 0.7827738616605521,
      "eval_loss": 0.3230102062225342,
      "eval_mean_accuracy": 0.8400976683408059,
      "eval_mean_iou": 0.7177230065160527,
      "eval_runtime": 52.8958,
      "eval_samples_per_second": 5.993,
      "eval_steps_per_second": 5.993,
      "step": 6435
    },
    {
      "epoch": 9.021001050052503,
      "grad_norm": 0.4909716844558716,
      "learning_rate": 2.392167832167832e-05,
      "loss": 0.2924,
      "step": 6450
    },
    {
      "epoch": 9.091004550227511,
      "grad_norm": 0.49187228083610535,
      "learning_rate": 2.3641958041958045e-05,
      "loss": 0.2858,
      "step": 6500
    },
    {
      "epoch": 9.16100805040252,
      "grad_norm": 0.8272931575775146,
      "learning_rate": 2.3362237762237762e-05,
      "loss": 0.285,
      "step": 6550
    },
    {
      "epoch": 9.231011550577529,
      "grad_norm": 0.40558579564094543,
      "learning_rate": 2.3082517482517483e-05,
      "loss": 0.2829,
      "step": 6600
    },
    {
      "epoch": 9.301015050752538,
      "grad_norm": 0.8437399864196777,
      "learning_rate": 2.2802797202797204e-05,
      "loss": 0.2839,
      "step": 6650
    },
    {
      "epoch": 9.371018550927547,
      "grad_norm": 0.9618678689002991,
      "learning_rate": 2.252307692307692e-05,
      "loss": 0.2789,
      "step": 6700
    },
    {
      "epoch": 9.441022051102555,
      "grad_norm": 0.48627790808677673,
      "learning_rate": 2.2243356643356642e-05,
      "loss": 0.2968,
      "step": 6750
    },
    {
      "epoch": 9.511025551277564,
      "grad_norm": 0.7460153102874756,
      "learning_rate": 2.1963636363636366e-05,
      "loss": 0.2776,
      "step": 6800
    },
    {
      "epoch": 9.581029051452573,
      "grad_norm": 0.9501960873603821,
      "learning_rate": 2.1683916083916084e-05,
      "loss": 0.2815,
      "step": 6850
    },
    {
      "epoch": 9.651032551627582,
      "grad_norm": 1.405063509941101,
      "learning_rate": 2.1404195804195805e-05,
      "loss": 0.2946,
      "step": 6900
    },
    {
      "epoch": 9.72103605180259,
      "grad_norm": 0.9799855351448059,
      "learning_rate": 2.1124475524475526e-05,
      "loss": 0.2817,
      "step": 6950
    },
    {
      "epoch": 9.7910395519776,
      "grad_norm": 0.24978600442409515,
      "learning_rate": 2.0844755244755243e-05,
      "loss": 0.2739,
      "step": 7000
    },
    {
      "epoch": 9.861043052152608,
      "grad_norm": 0.5829748511314392,
      "learning_rate": 2.0565034965034964e-05,
      "loss": 0.2816,
      "step": 7050
    },
    {
      "epoch": 9.931046552327617,
      "grad_norm": 0.29430335760116577,
      "learning_rate": 2.0285314685314685e-05,
      "loss": 0.2718,
      "step": 7100
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.7172377109527588,
      "learning_rate": 2.0005594405594406e-05,
      "loss": 0.2708,
      "step": 7150
    },
    {
      "epoch": 10.0,
      "eval_accuracy_landscape": 0.7732465197874666,
      "eval_loss": 0.3193550407886505,
      "eval_mean_accuracy": 0.8487095081683969,
      "eval_mean_iou": 0.7182166589343466,
      "eval_runtime": 56.0262,
      "eval_samples_per_second": 5.658,
      "eval_steps_per_second": 5.658,
      "step": 7150
    },
    {
      "epoch": 10.070003500175009,
      "grad_norm": 4.102182388305664,
      "learning_rate": 1.9725874125874127e-05,
      "loss": 0.2745,
      "step": 7200
    },
    {
      "epoch": 10.140007000350018,
      "grad_norm": 0.6368164420127869,
      "learning_rate": 1.9446153846153847e-05,
      "loss": 0.2738,
      "step": 7250
    },
    {
      "epoch": 10.210010500525026,
      "grad_norm": 0.3249545693397522,
      "learning_rate": 1.9166433566433568e-05,
      "loss": 0.2721,
      "step": 7300
    },
    {
      "epoch": 10.280014000700035,
      "grad_norm": 0.5163047909736633,
      "learning_rate": 1.8886713286713286e-05,
      "loss": 0.2702,
      "step": 7350
    },
    {
      "epoch": 10.350017500875044,
      "grad_norm": 0.43738093972206116,
      "learning_rate": 1.8606993006993007e-05,
      "loss": 0.2794,
      "step": 7400
    },
    {
      "epoch": 10.420021001050053,
      "grad_norm": 0.684992790222168,
      "learning_rate": 1.832727272727273e-05,
      "loss": 0.2922,
      "step": 7450
    },
    {
      "epoch": 10.490024501225061,
      "grad_norm": 2.017461061477661,
      "learning_rate": 1.8047552447552448e-05,
      "loss": 0.2857,
      "step": 7500
    },
    {
      "epoch": 10.56002800140007,
      "grad_norm": 0.3182847499847412,
      "learning_rate": 1.776783216783217e-05,
      "loss": 0.2764,
      "step": 7550
    },
    {
      "epoch": 10.630031501575079,
      "grad_norm": 0.4758036732673645,
      "learning_rate": 1.748811188811189e-05,
      "loss": 0.2805,
      "step": 7600
    },
    {
      "epoch": 10.700035001750088,
      "grad_norm": 0.3348321318626404,
      "learning_rate": 1.7208391608391607e-05,
      "loss": 0.2793,
      "step": 7650
    },
    {
      "epoch": 10.770038501925097,
      "grad_norm": 0.43814289569854736,
      "learning_rate": 1.6928671328671328e-05,
      "loss": 0.279,
      "step": 7700
    },
    {
      "epoch": 10.840042002100105,
      "grad_norm": 0.9312421083450317,
      "learning_rate": 1.6648951048951052e-05,
      "loss": 0.2668,
      "step": 7750
    },
    {
      "epoch": 10.910045502275114,
      "grad_norm": 0.5566179752349854,
      "learning_rate": 1.636923076923077e-05,
      "loss": 0.304,
      "step": 7800
    },
    {
      "epoch": 10.980049002450123,
      "grad_norm": 0.5157505869865417,
      "learning_rate": 1.608951048951049e-05,
      "loss": 0.2799,
      "step": 7850
    },
    {
      "epoch": 11.0,
      "eval_accuracy_landscape": 0.7769364532052621,
      "eval_loss": 0.31785640120506287,
      "eval_mean_accuracy": 0.8465964467177318,
      "eval_mean_iou": 0.7202588070414924,
      "eval_runtime": 60.4197,
      "eval_samples_per_second": 5.247,
      "eval_steps_per_second": 5.247,
      "step": 7865
    },
    {
      "epoch": 11.049002450122506,
      "grad_norm": 0.5231651067733765,
      "learning_rate": 1.580979020979021e-05,
      "loss": 0.2856,
      "step": 7900
    },
    {
      "epoch": 11.119005950297515,
      "grad_norm": 0.7626219391822815,
      "learning_rate": 1.553006993006993e-05,
      "loss": 0.2881,
      "step": 7950
    },
    {
      "epoch": 11.189009450472524,
      "grad_norm": 0.766840934753418,
      "learning_rate": 1.525034965034965e-05,
      "loss": 0.2778,
      "step": 8000
    },
    {
      "epoch": 11.259012950647532,
      "grad_norm": 1.3439466953277588,
      "learning_rate": 1.497062937062937e-05,
      "loss": 0.2753,
      "step": 8050
    },
    {
      "epoch": 11.329016450822541,
      "grad_norm": 0.36039602756500244,
      "learning_rate": 1.4690909090909092e-05,
      "loss": 0.2688,
      "step": 8100
    },
    {
      "epoch": 11.39901995099755,
      "grad_norm": 1.606969952583313,
      "learning_rate": 1.4411188811188812e-05,
      "loss": 0.2767,
      "step": 8150
    },
    {
      "epoch": 11.469023451172559,
      "grad_norm": 0.7680045366287231,
      "learning_rate": 1.4131468531468532e-05,
      "loss": 0.2808,
      "step": 8200
    },
    {
      "epoch": 11.539026951347568,
      "grad_norm": 0.5508187413215637,
      "learning_rate": 1.3851748251748252e-05,
      "loss": 0.2734,
      "step": 8250
    },
    {
      "epoch": 11.609030451522576,
      "grad_norm": 0.4335954785346985,
      "learning_rate": 1.3572027972027972e-05,
      "loss": 0.2845,
      "step": 8300
    },
    {
      "epoch": 11.679033951697585,
      "grad_norm": 1.8276690244674683,
      "learning_rate": 1.3292307692307692e-05,
      "loss": 0.2894,
      "step": 8350
    },
    {
      "epoch": 11.749037451872594,
      "grad_norm": 0.2859441339969635,
      "learning_rate": 1.3012587412587413e-05,
      "loss": 0.2863,
      "step": 8400
    },
    {
      "epoch": 11.819040952047603,
      "grad_norm": 0.8278273344039917,
      "learning_rate": 1.2732867132867132e-05,
      "loss": 0.2638,
      "step": 8450
    },
    {
      "epoch": 11.889044452222612,
      "grad_norm": 0.6078639030456543,
      "learning_rate": 1.2453146853146853e-05,
      "loss": 0.2731,
      "step": 8500
    },
    {
      "epoch": 11.95904795239762,
      "grad_norm": 0.29360342025756836,
      "learning_rate": 1.2173426573426574e-05,
      "loss": 0.2746,
      "step": 8550
    },
    {
      "epoch": 12.0,
      "eval_accuracy_landscape": 0.8080110846826912,
      "eval_loss": 0.31993791460990906,
      "eval_mean_accuracy": 0.8464819702401457,
      "eval_mean_iou": 0.720250263762576,
      "eval_runtime": 50.3699,
      "eval_samples_per_second": 6.293,
      "eval_steps_per_second": 6.293,
      "step": 8580
    },
    {
      "epoch": 12.028001400070004,
      "grad_norm": 0.955468475818634,
      "learning_rate": 1.1893706293706293e-05,
      "loss": 0.2833,
      "step": 8600
    },
    {
      "epoch": 12.098004900245012,
      "grad_norm": 0.9115980863571167,
      "learning_rate": 1.1613986013986014e-05,
      "loss": 0.2765,
      "step": 8650
    },
    {
      "epoch": 12.168008400420021,
      "grad_norm": 0.4655108153820038,
      "learning_rate": 1.1334265734265735e-05,
      "loss": 0.2905,
      "step": 8700
    },
    {
      "epoch": 12.23801190059503,
      "grad_norm": 0.318602055311203,
      "learning_rate": 1.1054545454545454e-05,
      "loss": 0.2822,
      "step": 8750
    },
    {
      "epoch": 12.308015400770039,
      "grad_norm": 0.8647976517677307,
      "learning_rate": 1.0774825174825175e-05,
      "loss": 0.2631,
      "step": 8800
    },
    {
      "epoch": 12.378018900945047,
      "grad_norm": 1.314572811126709,
      "learning_rate": 1.0495104895104896e-05,
      "loss": 0.2674,
      "step": 8850
    },
    {
      "epoch": 12.448022401120056,
      "grad_norm": 0.7753697633743286,
      "learning_rate": 1.0215384615384615e-05,
      "loss": 0.2917,
      "step": 8900
    },
    {
      "epoch": 12.518025901295065,
      "grad_norm": 0.8186022639274597,
      "learning_rate": 9.935664335664336e-06,
      "loss": 0.2855,
      "step": 8950
    },
    {
      "epoch": 12.588029401470074,
      "grad_norm": 0.37156030535697937,
      "learning_rate": 9.655944055944057e-06,
      "loss": 0.2821,
      "step": 9000
    },
    {
      "epoch": 12.658032901645083,
      "grad_norm": 1.335487961769104,
      "learning_rate": 9.376223776223776e-06,
      "loss": 0.275,
      "step": 9050
    },
    {
      "epoch": 12.728036401820091,
      "grad_norm": 0.5250369906425476,
      "learning_rate": 9.096503496503497e-06,
      "loss": 0.2745,
      "step": 9100
    },
    {
      "epoch": 12.7980399019951,
      "grad_norm": 0.7540001273155212,
      "learning_rate": 8.816783216783218e-06,
      "loss": 0.2603,
      "step": 9150
    },
    {
      "epoch": 12.868043402170109,
      "grad_norm": 1.5403181314468384,
      "learning_rate": 8.537062937062937e-06,
      "loss": 0.2725,
      "step": 9200
    },
    {
      "epoch": 12.938046902345118,
      "grad_norm": 0.7419692873954773,
      "learning_rate": 8.257342657342658e-06,
      "loss": 0.2731,
      "step": 9250
    },
    {
      "epoch": 13.0,
      "eval_accuracy_landscape": 0.7928807580607636,
      "eval_loss": 0.32163187861442566,
      "eval_mean_accuracy": 0.8503898380807142,
      "eval_mean_iou": 0.7184232407897575,
      "eval_runtime": 50.5095,
      "eval_samples_per_second": 6.276,
      "eval_steps_per_second": 6.276,
      "step": 9295
    },
    {
      "epoch": 13.0070003500175,
      "grad_norm": 0.5984437465667725,
      "learning_rate": 7.977622377622378e-06,
      "loss": 0.2779,
      "step": 9300
    },
    {
      "epoch": 13.07700385019251,
      "grad_norm": 0.39819130301475525,
      "learning_rate": 7.697902097902098e-06,
      "loss": 0.2752,
      "step": 9350
    },
    {
      "epoch": 13.147007350367518,
      "grad_norm": 1.625918984413147,
      "learning_rate": 7.4181818181818185e-06,
      "loss": 0.2825,
      "step": 9400
    },
    {
      "epoch": 13.217010850542527,
      "grad_norm": 1.371930480003357,
      "learning_rate": 7.1384615384615385e-06,
      "loss": 0.2747,
      "step": 9450
    },
    {
      "epoch": 13.287014350717536,
      "grad_norm": 0.9071800708770752,
      "learning_rate": 6.858741258741259e-06,
      "loss": 0.2873,
      "step": 9500
    },
    {
      "epoch": 13.357017850892545,
      "grad_norm": 0.2717413008213043,
      "learning_rate": 6.579020979020979e-06,
      "loss": 0.277,
      "step": 9550
    },
    {
      "epoch": 13.427021351067554,
      "grad_norm": 3.8726372718811035,
      "learning_rate": 6.299300699300699e-06,
      "loss": 0.2836,
      "step": 9600
    },
    {
      "epoch": 13.497024851242562,
      "grad_norm": 0.56602942943573,
      "learning_rate": 6.01958041958042e-06,
      "loss": 0.2679,
      "step": 9650
    },
    {
      "epoch": 13.567028351417571,
      "grad_norm": 0.5564559698104858,
      "learning_rate": 5.739860139860139e-06,
      "loss": 0.2756,
      "step": 9700
    },
    {
      "epoch": 13.63703185159258,
      "grad_norm": 0.6512941718101501,
      "learning_rate": 5.46013986013986e-06,
      "loss": 0.2745,
      "step": 9750
    },
    {
      "epoch": 13.707035351767589,
      "grad_norm": 0.47870275378227234,
      "learning_rate": 5.180419580419581e-06,
      "loss": 0.2726,
      "step": 9800
    },
    {
      "epoch": 13.777038851942597,
      "grad_norm": 0.3313717842102051,
      "learning_rate": 4.900699300699301e-06,
      "loss": 0.2743,
      "step": 9850
    },
    {
      "epoch": 13.847042352117606,
      "grad_norm": 0.4046232998371124,
      "learning_rate": 4.620979020979021e-06,
      "loss": 0.2755,
      "step": 9900
    },
    {
      "epoch": 13.917045852292615,
      "grad_norm": 1.6403146982192993,
      "learning_rate": 4.341258741258742e-06,
      "loss": 0.2884,
      "step": 9950
    },
    {
      "epoch": 13.987049352467624,
      "grad_norm": 4.470865726470947,
      "learning_rate": 4.061538461538462e-06,
      "loss": 0.2686,
      "step": 10000
    },
    {
      "epoch": 14.0,
      "eval_accuracy_landscape": 0.7783997410658295,
      "eval_loss": 0.31359434127807617,
      "eval_mean_accuracy": 0.8484611175003975,
      "eval_mean_iou": 0.7221915430630643,
      "eval_runtime": 51.9036,
      "eval_samples_per_second": 6.107,
      "eval_steps_per_second": 6.107,
      "step": 10010
    }
  ],
  "logging_steps": 50,
  "max_steps": 10725,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.011801743512044e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
